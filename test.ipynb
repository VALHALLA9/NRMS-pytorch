{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:38:46) [MSC v.1929 64 bit (AMD64)]\n",
      "PyTorch version: 2.3.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 8700\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "x: tensor([1., 2., 3.], device='cuda:0')\n",
      "y: tensor([4., 5., 6.], device='cuda:0')\n",
      "z: tensor([5., 7., 9.], device='cuda:0') (on cuda)\n",
      "Current GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")  \n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")  \n",
    "\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "y = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "\n",
    "\n",
    "z = x + y\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"z: {z} (on {device})\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 10, 64])\n",
      "Attention weights shape: torch.Size([4, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "seq_len = 10\n",
    "embed_dim = 64  \n",
    "num_heads = 8   \n",
    "\n",
    "#  MultiheadAttention\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "#  (batch_size, seq_len, embed_dim)\n",
    "query = torch.rand(batch_size, seq_len, embed_dim)  # Q\n",
    "key = torch.rand(batch_size, seq_len, embed_dim)    # K\n",
    "value = torch.rand(batch_size, seq_len, embed_dim)  # V\n",
    "\n",
    "\n",
    "output, attn_weights = multihead_attn(query, key, value)\n",
    "\n",
    "print(\"Output shape:\", output.shape)               # (batch_size, seq_len, embed_dim)\n",
    "print(\"Attention weights shape:\", attn_weights.shape)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshape: torch.Size([32, 20, 64])\n",
      "Output shape: torch.Size([32, 20, 64])\n",
      "Attention weights shape: torch.Size([32, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MyModel, self).__init__()\n",
    "        # \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, H, F = x.shape\n",
    "\n",
    "\n",
    "        x = x.view(B, H, F)\n",
    "        print(f\"After reshape: {x.shape}\")\n",
    "\n",
    "        # MultiheadAttention expects inputs in the form (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        output, attn_weights = self.attention(x, x, x)\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Attention weights shape: {attn_weights.shape}\")\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "B, H, F = 32, 20, 64  # Batch size, Sequence length, Embedding dimension\n",
    "num_heads = 8\n",
    "x = torch.randn(B, H, F)  \n",
    "\n",
    "model = MyModel(embed_dim=F, num_heads=num_heads)\n",
    "output = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before softmax:\n",
      "tensor([[-2.3936, -0.7790, -0.3967, -0.8505,  0.0509],\n",
      "        [ 0.2480, -0.5122, -0.7802,  1.2352,  1.5804],\n",
      "        [-0.5679, -1.5157,  0.4523,  0.9482,  0.0849],\n",
      "        [-0.1517,  1.1859, -0.1958, -0.1723,  0.1180],\n",
      "        [ 0.5610,  0.9170, -0.6280,  0.8250,  0.5983],\n",
      "        [-0.3074, -1.7504, -0.1745,  0.4617, -1.0566],\n",
      "        [ 0.9257,  1.2592, -2.3153, -0.7699, -0.5144],\n",
      "        [-0.4343, -0.7214, -1.2467,  0.6687, -0.1391],\n",
      "        [-0.2405, -0.7276,  0.9328, -1.1414, -0.1175],\n",
      "        [ 1.5703, -0.2622,  0.8426,  0.7560,  0.6770],\n",
      "        [-0.7653,  1.6279,  0.9796, -0.8113, -0.4846],\n",
      "        [ 0.4852,  1.1089, -1.0230, -0.9203,  0.8567],\n",
      "        [-0.4231, -0.4528,  0.7385, -0.1007, -0.6254],\n",
      "        [-0.8582,  0.0659, -0.3369,  0.1153,  1.1516],\n",
      "        [ 1.5190,  0.0485,  0.9633,  1.1710,  0.4995],\n",
      "        [-0.3589, -0.6403, -0.2113,  0.9878,  1.0411],\n",
      "        [-0.2826, -0.5999, -2.0255,  0.2208,  0.6662],\n",
      "        [-1.5142, -2.6993, -0.3244,  0.8340, -0.7201],\n",
      "        [ 0.8983, -0.7819,  0.3330,  0.5778, -0.6757],\n",
      "        [ 0.3237,  1.0258, -0.6190, -2.0107,  0.6807],\n",
      "        [-0.7435, -0.3707,  0.1200, -0.7207,  1.6553],\n",
      "        [ 0.6724, -1.1203,  0.5088,  1.1579, -0.4269],\n",
      "        [-0.6513, -0.1410, -2.5856,  0.6219,  0.2418],\n",
      "        [-0.8942, -1.2756, -1.0626, -0.6949,  0.6422],\n",
      "        [-0.2017, -0.2631,  0.4229,  0.4669, -1.0913],\n",
      "        [-0.7559, -0.8437,  1.8401, -0.0655, -0.6243],\n",
      "        [-0.7540, -2.3154, -1.9213, -1.0387, -1.0993],\n",
      "        [ 1.2597, -0.2368, -0.2882, -0.5804, -0.9900],\n",
      "        [-1.1972,  1.2684, -0.3789,  1.6285, -2.7426],\n",
      "        [-0.2069, -1.4775,  1.1672,  0.3074,  0.2618],\n",
      "        [-0.4026,  0.3561, -0.0528, -1.0599,  0.2427],\n",
      "        [-0.6619,  1.3075,  1.0056, -0.8094, -0.3052]])\n",
      "After softmax:\n",
      "tensor([[0.0338, 0.1698, 0.2489, 0.1581, 0.3894],\n",
      "        [0.1205, 0.0563, 0.0431, 0.3234, 0.4567],\n",
      "        [0.0940, 0.0364, 0.2608, 0.4282, 0.1806],\n",
      "        [0.1241, 0.4729, 0.1188, 0.1216, 0.1626],\n",
      "        [0.1971, 0.2815, 0.0600, 0.2567, 0.2046],\n",
      "        [0.1996, 0.0472, 0.2280, 0.4308, 0.0944],\n",
      "        [0.3502, 0.4889, 0.0137, 0.0643, 0.0830],\n",
      "        [0.1527, 0.1146, 0.0677, 0.4600, 0.2051],\n",
      "        [0.1566, 0.0962, 0.5064, 0.0636, 0.1771],\n",
      "        [0.4008, 0.0641, 0.1936, 0.1775, 0.1640],\n",
      "        [0.0501, 0.5487, 0.2870, 0.0479, 0.0664],\n",
      "        [0.2091, 0.3902, 0.0463, 0.0513, 0.3032],\n",
      "        [0.1358, 0.1318, 0.4339, 0.1875, 0.1109],\n",
      "        [0.0653, 0.1645, 0.1100, 0.1729, 0.4873],\n",
      "        [0.3484, 0.0801, 0.1999, 0.2460, 0.1257],\n",
      "        [0.0925, 0.0698, 0.1072, 0.3555, 0.3750],\n",
      "        [0.1629, 0.1186, 0.0285, 0.2694, 0.4206],\n",
      "        [0.0579, 0.0177, 0.1903, 0.6060, 0.1281],\n",
      "        [0.3721, 0.0693, 0.2114, 0.2701, 0.0771],\n",
      "        [0.2027, 0.4090, 0.0790, 0.0196, 0.2897],\n",
      "        [0.0593, 0.0861, 0.1407, 0.0607, 0.6532],\n",
      "        [0.2517, 0.0419, 0.2137, 0.4089, 0.0838],\n",
      "        [0.1133, 0.1888, 0.0164, 0.4048, 0.2768],\n",
      "        [0.1191, 0.0813, 0.1006, 0.1454, 0.5536],\n",
      "        [0.1621, 0.1524, 0.3027, 0.3163, 0.0666],\n",
      "        [0.0542, 0.0496, 0.7264, 0.1080, 0.0618],\n",
      "        [0.3354, 0.0704, 0.1044, 0.2523, 0.2375],\n",
      "        [0.5879, 0.1316, 0.1251, 0.0934, 0.0620],\n",
      "        [0.0311, 0.3664, 0.0706, 0.5252, 0.0066],\n",
      "        [0.1176, 0.0330, 0.4648, 0.1967, 0.1879],\n",
      "        [0.1433, 0.3060, 0.2033, 0.0743, 0.2732],\n",
      "        [0.0635, 0.4548, 0.3363, 0.0548, 0.0907]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example\n",
    "preds = torch.randn(32, 5)  # Shape: (B=32, N=5)\n",
    "print(\"Before softmax:\")\n",
    "print(preds)\n",
    "\n",
    "# Apply softmax along the last dimension (-1)\n",
    "preds = F.softmax(preds, dim=-1)\n",
    "print(\"After softmax:\")\n",
    "print(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
